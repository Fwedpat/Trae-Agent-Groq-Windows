Two new features have been added:

    ðŸªŸ Windows Support

        The CLI now runs natively on Windows (PowerShell or CMD).

        No need for WSL or Linux/macOS environments. Git Bash is required.

    ðŸ¤– GROQ Provider Integration

        Added support for using GROQ as an LLM provider alongside existing ones like OpenAI, Anthropic, and OpenRouter.

        Enables access to models like Qwen3, Kimi-K2, etc. via GROQ's fast inference API.

These enhancements make the project more cross-platform and offer more LLM backend flexibility.
